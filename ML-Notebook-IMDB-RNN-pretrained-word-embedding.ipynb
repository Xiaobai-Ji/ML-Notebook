{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOe7bJauDWnVF74UgnMXDho"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnMqf2hRNk8w",
        "colab_type": "code",
        "outputId": "e8df950e-8e29-4006-c3f1-5f538062b542",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "!nvidia-smi\n",
        "\n",
        "import tensorflow as tf\n",
        "print('is GPU available: ', tf.test.is_gpu_available())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Feb  5 08:27:52 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.48.02    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "is GPU available:  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miZ3AW0gNpaJ",
        "colab_type": "code",
        "outputId": "aafd5feb-7322-49a4-dba2-3c0dc22d65fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "!wget http://mng.bz/0tIo --no-check-certificate"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-05 08:30:24--  http://mng.bz/0tIo\n",
            "Resolving mng.bz (mng.bz)... 35.166.24.88\n",
            "Connecting to mng.bz (mng.bz)|35.166.24.88|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://mng.bz/0tIo [following]\n",
            "--2020-02-05 08:30:24--  https://mng.bz/0tIo\n",
            "Connecting to mng.bz (mng.bz)|35.166.24.88|:443... connected.\n",
            "WARNING: cannot verify mng.bz's certificate, issued by ‘CN=Go Daddy Secure Certificate Authority - G2,OU=http://certs.godaddy.com/repository/,O=GoDaddy.com\\\\, Inc.,L=Scottsdale,ST=Arizona,C=US’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 301 \n",
            "Location: http://s3.amazonaws.com/text-datasets/aclImdb.zip [following]\n",
            "--2020-02-05 08:30:25--  http://s3.amazonaws.com/text-datasets/aclImdb.zip\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.184.165\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.184.165|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 60711700 (58M) [application/zip]\n",
            "Saving to: ‘0tIo’\n",
            "\n",
            "0tIo                100%[===================>]  57.90M  27.2MB/s    in 2.1s    \n",
            "\n",
            "2020-02-05 08:30:27 (27.2 MB/s) - ‘0tIo’ saved [60711700/60711700]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjtRc_PkNuII",
        "colab_type": "code",
        "outputId": "7bbf67e6-68b1-436e-9e09-cbaf5287a1a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!unzip -q 0tIo\n",
        "!rm -rf __MACOSX sample_data\n",
        "!ls"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0tIo  aclImdb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAzmi8TpOEon",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "imdb_dir = '/content/aclImdb/'\n",
        "train_dir = os.path.join(imdb_dir, 'train')\n",
        "\n",
        "labels = []\n",
        "texts = []\n",
        "\n",
        "for label_type in ['neg', 'pos']:\n",
        "  dir_name = os.path.join(train_dir, label_type)\n",
        "  for fname in os.listdir(dir_name):\n",
        "    if fname[-4:] == '.txt':\n",
        "      f = open(os.path.join(dir_name, fname))\n",
        "      texts.append(f.read())\n",
        "      f.close()\n",
        "      if label_type == 'neg':\n",
        "        labels.append(0)\n",
        "      else:\n",
        "        labels.append(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9aba4ada-a2c7-4440-ec7a-b5a441abb355",
        "id": "wYGs-D5hec_V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "maxlen = 100\n",
        "training_samples = 200\n",
        "validation_samples = 10000\n",
        "max_words = 10000\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('found %s unique tokens' % len(word_index))\n",
        "\n",
        "data = pad_sequences(sequences, maxlen=maxlen) # cut off or make up to 100 words of each comments\n",
        "\n",
        "labels = np.asarray(labels)\n",
        "print('shape of data tensor: ', data.shape)\n",
        "print('shape of label tensor: ', labels.shape)\n",
        "\n",
        "# shuffling dataset\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "x_train = data[:training_samples]\n",
        "y_train = labels[:training_samples]\n",
        "x_val = data[training_samples: training_samples + validation_samples]\n",
        "y_val = labels[training_samples: training_samples + validation_samples]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "found 88582 unique tokens\n",
            "shape of data tensor:  (25000, 100)\n",
            "shape of label tensor:  (25000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTY69Qx_RVo9",
        "colab_type": "code",
        "outputId": "ed64495c-5e9a-4c87-e1f8-f13e9abdb565",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "!rm -rf glove.6B.50d.txt glove.6B.100d.txt glove.6B.200d.txt glove.6B.300d.txt\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -qq glove.6B.zip -d glove\n",
        "!rm -rf glove.6B.zip"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-05 09:02:48--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-02-05 09:02:48--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-02-05 09:02:48--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  1.98MB/s    in 6m 29s  \n",
            "\n",
            "2020-02-05 09:09:18 (2.11 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W55S7gcHTdJH",
        "colab_type": "code",
        "outputId": "5d4017e5-c10a-44a6-af41-4e95a19666ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "glove_dir = '/content/glove'\n",
        "\n",
        "embeddings_index = {}\n",
        "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
        "\n",
        "i = 0\n",
        "for line in f:\n",
        "  i = i+1\n",
        "  if i == 1:\n",
        "    print(line)\n",
        "  values = line.split()\n",
        "  word = values[0]\n",
        "  coefs = np.asarray(values[1:], dtype='float32')\n",
        "  embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print(i)\n",
        "print('found %s word vectors' % len(embeddings_index))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the -0.038194 -0.24487 0.72812 -0.39961 0.083172 0.043953 -0.39141 0.3344 -0.57545 0.087459 0.28787 -0.06731 0.30906 -0.26384 -0.13231 -0.20757 0.33395 -0.33848 -0.31743 -0.48336 0.1464 -0.37304 0.34577 0.052041 0.44946 -0.46971 0.02628 -0.54155 -0.15518 -0.14107 -0.039722 0.28277 0.14393 0.23464 -0.31021 0.086173 0.20397 0.52624 0.17164 -0.082378 -0.71787 -0.41531 0.20335 -0.12763 0.41367 0.55187 0.57908 -0.33477 -0.36559 -0.54857 -0.062892 0.26584 0.30205 0.99775 -0.80481 -3.0243 0.01254 -0.36942 2.2167 0.72201 -0.24978 0.92136 0.034514 0.46745 1.1079 -0.19358 -0.074575 0.23353 -0.052062 -0.22044 0.057162 -0.15806 -0.30798 -0.41625 0.37972 0.15006 -0.53212 -0.2055 -1.2526 0.071624 0.70565 0.49744 -0.42063 0.26148 -1.538 -0.30223 -0.073438 -0.28312 0.37104 -0.25217 0.016215 -0.017099 -0.38984 0.87424 -0.72569 -0.51058 -0.52028 -0.1459 0.8278 0.27062\n",
            "\n",
            "400000\n",
            "found 400000 word vectors\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMGdCm8fU2Eg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim = 100\n",
        "\n",
        "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "  if i < max_words:\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib4fQgXvVN-y",
        "colab_type": "code",
        "outputId": "12922f8a-b662-4a1b-ba25-84ccdf545964",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 100, 100)          1000000   \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 10000)             0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 32)                320032    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 1,320,065\n",
            "Trainable params: 1,320,065\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjVa8DCKXEZs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.layers[0].set_weights([embedding_matrix])\n",
        "model.layers[0].trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lc0nlOGdXpk-",
        "colab_type": "code",
        "outputId": "ef498107-47ab-43ab-f745-731f6dff7891",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc']) \n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_val, y_val))\n",
        "model.save_weights('pre_trained_glove_model.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 200 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 1.7420 - acc: 0.4800 - val_loss: 0.7304 - val_acc: 0.4980\n",
            "Epoch 2/10\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.7000 - acc: 0.5850 - val_loss: 0.7182 - val_acc: 0.5018\n",
            "Epoch 3/10\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.4365 - acc: 0.8200 - val_loss: 0.9309 - val_acc: 0.5027\n",
            "Epoch 4/10\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.3860 - acc: 0.8300 - val_loss: 1.1383 - val_acc: 0.5021\n",
            "Epoch 5/10\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.3310 - acc: 0.8800 - val_loss: 0.7642 - val_acc: 0.4957\n",
            "Epoch 6/10\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.3977 - acc: 0.8200 - val_loss: 0.8188 - val_acc: 0.4984\n",
            "Epoch 7/10\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1508 - acc: 0.9950 - val_loss: 0.8047 - val_acc: 0.5009\n",
            "Epoch 8/10\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0830 - acc: 1.0000 - val_loss: 0.8094 - val_acc: 0.5038\n",
            "Epoch 9/10\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.2947 - acc: 0.8600 - val_loss: 0.7999 - val_acc: 0.4944\n",
            "Epoch 10/10\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0608 - acc: 1.0000 - val_loss: 0.8087 - val_acc: 0.5013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljY99NlxYLo0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dir = os.path.join(imdb_dir, 'test')\n",
        "labels = []\n",
        "texts = []\n",
        "\n",
        "for label_type in ['neg', 'pos']:\n",
        "  dir_name = os.path.join(test_dir, label_type)\n",
        "  for fname in sorted(os.listdir(dir_name)):\n",
        "    if fname[-4:] == '.txt':\n",
        "      f = open(os.path.join(dir_name, fname))\n",
        "      texts.append(f.read())\n",
        "      f.close()\n",
        "      if label_type == 'neg':\n",
        "        labels.append(0)\n",
        "      else:\n",
        "        labels.append(1)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "x_test = pad_sequences(sequences, maxlen=maxlen)\n",
        "y_test = np.asarray(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZdqoJKHeqdJ",
        "colab_type": "code",
        "outputId": "5dae1ae6-0008-4ea4-cff3-4d5e48776fd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.load_weights('pre_trained_glove_model.h5')\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 1s 43us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8146685246276856, 0.49772]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_6Zvs8ietFq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}